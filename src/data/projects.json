[
  {
    "icon": "üß†",
    "title": "LLM Rorschach",
    "description": "What if LLMs could expose your biases instead of just parroting them? A prototype exploring LLM behaviors through ambiguous prompts and analyzing subjective interpretations.",
    "tools": "Python, OpenAI API, Prompt Engineering",
    "status": "In Progress",
    "statusColor": "bg-indigo-600",
    "priority": 1,
    "year": 2025,
    "category": "AI",
    "collab": "Solo",
    "link": ""
  },
  {
    "icon": "üßÆ",
    "title": "Risk Workflow Reviver",
    "description": "Turning spaghetti processes into sleek systems. A reconstruction of broken Excel-based risk ops workflows at scale ‚Äî automating reports, flagging errors, and reducing manual drag.",
    "tools": "Python, VBA, SQL",
    "status": "Case study coming soon",
    "statusColor": "bg-yellow-600",
    "priority": 3,
    "year": 2024,
    "category": "Systems",
    "collab": "Team",
    "link": ""
  },
  {
    "icon": "üîç",
    "title": "AI Ethics Tracker",
    "description": "Not all AI is created equal ‚Äî let‚Äôs keep score. A browser-based tool to monitor AI deployments across sectors, tracking transparency, consent, and alignment with ethical principles.",
    "tools": "Streamlit, Python, Web scraping",
    "status": "Early prototype",
    "statusColor": "bg-indigo-600",
    "priority": 2,
    "year": 2025,
    "category": "Ethics",
    "collab": "Solo",
    "link": ""
  },
  {
    "icon": "üí∏",
    "title": "Algo Transparency Audit",
    "description": "Follow the money, follow the model. A system to evaluate black-box algorithms in fintech for explainability, impact, and fairness.",
    "tools": "Python, SHAP, Model interpretability frameworks",
    "status": "Coming soon",
    "statusColor": "bg-yellow-600",
    "priority": 4,
    "year": 2025,
    "category": "AI",
    "collab": "Team",
    "link": ""
  },
  {
    "icon": "üí≠",
    "title": "Systems Thinking Sandbox",
    "description": "Where code meets 'why?' Experimental builds that test cause-effect loops, unintended consequences, and incentive design through mini simulations.",
    "tools": "Python, Simulations, Rule-based engines",
    "status": "Playground coming soon",
    "statusColor": "bg-yellow-600",
    "priority": 5,
    "year": 2024,
    "category": "Philosophy",
    "collab": "Solo",
    "link": ""
  },
  {
    "icon": "üåÄ",
    "title": "Prompting the Ship of Theseus",
    "description": "When large language models meet large existential questions. üó£Ô∏è Prompting the Ship of Theseus ‚Äî a philosophical experiment with fine-tuning and prompt chaining to explore identity, continuity, and consciousness through an LLM‚Äôs responses.",
    "tools": "OpenAI API, Python, Prompt Engineering",
    "status": "Blog + demo coming",
    "statusColor": "bg-yellow-600",
    "priority": 6,
    "year": 2025,
    "category": "Philosophy",
    "collab": "Solo",
    "link": ""
  },
  {
    "icon": "üß≠",
    "title": "LLM Moral Compass",
    "description": "Do LLMs have morals or just pattern-matching ethics? A series of controlled prompts to test ethical reasoning across dilemmas (trolley problem, lying, fairness).",
    "tools": "Python, Prompt evaluation, OpenAI API",
    "status": "Experiment live soon",
    "statusColor": "bg-indigo-600",
    "priority": 7,
    "year": 2025,
    "category": "Ethics",
    "collab": "Solo",
    "link": ""
  },
  {
    "icon": "üí¨",
    "title": "The Simulated Philosopher",
    "description": "Chatting with Socrates, but make it LLM. Built an LLM-powered agent that follows the Socratic method ‚Äî it doesn‚Äôt answer, it just questions your beliefs till you do.",
    "tools": "Python, LangChain, LLM agents",
    "status": "Beta version coming",
    "statusColor": "bg-yellow-600",
    "priority": 8,
    "year": 2025,
    "category": "Philosophy",
    "collab": "Solo",
    "link": ""
  }
]
